{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BP算法分析与实现  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 反向传播算法  \n",
    "[**一个介绍反向传播算法的文章，本代码依据此文章的公式实现**](https://blog.csdn.net/fsfjdtpzus/article/details/106256925)  \n",
    "- 代码写的有点烂，不是很规范  \n",
    "- 可以自定义Layer，保证输入是2，输出是1以及前一层的输出和后一层的输入相同即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22199317, 0.87073231, 0.20671916, 0.91861091, 0.48841119],\n",
       "       [0.61174386, 0.76590786, 0.51841799, 0.2968005 , 0.18772123]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "np.random.random((2,5))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义任意一层的类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate=0.1  \n",
    "class Layer():\n",
    "    def __init__(self,input_size,output_size,learn_rate=learn_rate):\n",
    "        self.input_size=input_size\n",
    "        self.output_size=output_size  \n",
    "        self.learn_rate=learn_rate  \n",
    "        self.input=None    \n",
    "        self.output=None  \n",
    "        np.random.seed(1412)\n",
    "        self.weights=np.random.random((output_size,input_size))  \n",
    "    def forward(self,x):#x是 1*input_size \n",
    "        self.input=x  \n",
    "        y=np.zeros(self.output_size)\n",
    "        for i in range(len(y)):\n",
    "            y[i]=self.weights[i].reshape(1,-1) @ x    \n",
    "        y=np.array([i if i>0 else 0.00001*i for i in y])#使用relu函数  \n",
    "        return y.reshape(-1,1)  \n",
    "    def backward(self,loss):#得到一个loss树组，长度=output_size\n",
    "        for ind1 in range(self.weights.shape[0]):\n",
    "            for ind2 in range(self.weights.shape[1]):\n",
    "                tmp=1 if self.input[ind2][0]>0 else 0.00001  \n",
    "                #更新权重  \n",
    "                self.weights[ind1][ind2]+=self.learn_rate*tmp*self.input[ind2][0]*loss[ind1][0]  \n",
    "        return self.weights    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义网络类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net():\n",
    "    def __init__(self,layers):\n",
    "        self.layers=layers  \n",
    "    def predict(self,x):\n",
    "        output=x\n",
    "        for ind in range(len(self.layers)):\n",
    "            output=self.layers[ind].forward(output)\n",
    "        return output  \n",
    "    def train(self,x,y):\n",
    "        #计算输出\n",
    "        output=x\n",
    "        for ind in range(len(self.layers)):\n",
    "            output=self.layers[ind].forward(output)\n",
    "        loss_out=y-output\n",
    "        loss_all_layers=[np.array(loss_out).reshape(-1,1)]\n",
    "        for ind in [i for i in range(len(self.layers))][::-1][:-1]:\n",
    "            tmp_loss=self.layers[ind].weights.T@loss_all_layers[-1]\n",
    "            loss_all_layers.append(tmp_loss)  \n",
    "        loss_all_layers=loss_all_layers[::-1]\n",
    "        for ind in [i for i in range(len(self.layers))][::-1]:\n",
    "            self.layers[ind].backward(loss_all_layers[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_list=[[Layer(2,3),Layer(3,2),Layer(2,1)],[Layer(2,1)]]\n",
    "x=[[0.35],[0.9]]\n",
    "y=[[0.5]]\n",
    "loss_list=[]\n",
    "for layers in layers_list:\n",
    "    losses=[]\n",
    "    net=Net(layers=layers)  \n",
    "    for i in range(40):\n",
    "        net.train(x,y)\n",
    "        losses.append((1/2)*np.sqrt((net.predict(x)[0][0]-y[0][0])**2))\n",
    "    loss_list.append(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 展示不同的结构的训练过程中的损失值以及预测值的变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   \n",
    "fig,ax=plt.subplots()\n",
    "fig.set_size_inches(10,6)\n",
    "ax.plot(np.linspace(0,len(loss_list[0]),len(loss_list[0])),loss_list[0],linewidth=1,c='b',label='3-layer')\n",
    "ax.plot(np.linspace(0,len(loss_list[1]),len(loss_list[1])),loss_list[1],linewidth=1,c='r',label='1-layer')\n",
    "ax.legend()\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
